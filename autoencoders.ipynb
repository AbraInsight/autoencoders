{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Author: Hamaad Musharaf Shah.\n",
    "# The following references were used.\n",
    "# https://keras.io\n",
    "# https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "# https://stackoverflow.com/questions/42177658/how-to-switch-backend-with-keras-from-tensorflow-to-theano\n",
    "# https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\n",
    "# http://scikit-learn.org/stable/\n",
    "# Book: Ian Goodfellow, Yoshua Bengio and Aaron Courville, \"Deep Learning\" - http://www.deeplearningbook.org\n",
    "# Book: Aurelien Geron, \"Hands-On Machine Learning with Scikit-Learn & Tensorflow\" - https://www.amazon.co.uk/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291\n",
    "\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "import keras\n",
    "from keras import backend as bkend\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from autoencoders_keras.vanilla_autoencoder import VanillaAutoencoder\n",
    "from autoencoders_keras.convolutional_autoencoder import ConvolutionalAutoencoder\n",
    "from autoencoders_keras.convolutional2D_autoencoder import Convolutional2DAutoencoder\n",
    "from autoencoders_keras.seq2seq_autoencoder import Seq2SeqAutoencoder\n",
    "from autoencoders_keras.variational_autoencoder import VariationalAutoencoder\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "importlib.reload(bkend)\n",
    "\n",
    "mnist = fetch_mldata(\"MNIST original\")\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X = X.astype(\"float32\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=666)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "scaler_classifier = MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "logistic = linear_model.LogisticRegression(random_state=666)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb = lb.fit(y_train.reshape(y_train.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_base = Pipeline(steps=[(\"scaler_classifier\", scaler_classifier),\n",
    "                            (\"classifier\", logistic)])\n",
    "pipe_base = pipe_base.fit(X_train, y_train)\n",
    "\n",
    "metric_base = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                            pipe_base.predict_proba(X_test), \n",
    "                            average=\"weighted\")\n",
    "print(metric_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoencoder = VanillaAutoencoder(n_feat=X_train.shape[1],\n",
    "                                 n_epoch=5,\n",
    "                                 batch_size=100,\n",
    "                                 encoder_layers=3,\n",
    "                                 decoder_layers=3,\n",
    "                                 n_hidden_units=int(X_train.shape[1] / 2),\n",
    "                                 encoding_dim=int(X_train.shape[1] / 2),\n",
    "                                 denoising=None)\n",
    "\n",
    "print(autoencoder.autoencoder.summary())\n",
    "\n",
    "pipe_autoencoder = Pipeline(steps=[(\"autoencoder\", autoencoder),\n",
    "                                   (\"scaler_classifier\", scaler_classifier),\n",
    "                                   (\"classifier\", logistic)])\n",
    "\n",
    "pipe_autoencoder = pipe_autoencoder.fit(X_train, y_train)\n",
    "\n",
    "metric_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                   pipe_autoencoder.predict_proba(X_test), \n",
    "                                   average=\"weighted\")\n",
    "print(metric_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noise = 0.05 * np.reshape(np.random.uniform(low=0.0, \n",
    "                                            high=1.0, \n",
    "                                            size=X_train.shape[0] * X_train.shape[1]), \n",
    "                          [X_train.shape[0], X_train.shape[1]])\n",
    "\n",
    "denoising_autoencoder = VanillaAutoencoder(n_feat=X_train.shape[1],\n",
    "                                           n_epoch=50,\n",
    "                                           batch_size=100,\n",
    "                                           encoder_layers=3,\n",
    "                                           decoder_layers=3,\n",
    "                                           n_hidden_units=int(X_train.shape[1] / 2),\n",
    "                                           encoding_dim=int(X_train.shape[1] / 2),\n",
    "                                           denoising=noise)\n",
    "\n",
    "print(denoising_autoencoder.autoencoder.summary())\n",
    "\n",
    "pipe_denoising_autoencoder = Pipeline(steps=[(\"autoencoder\", denoising_autoencoder),\n",
    "                                             (\"scaler_classifier\", scaler_classifier),\n",
    "                                             (\"classifier\", logistic)])\n",
    "\n",
    "pipe_denoising_autoencoder = pipe_denoising_autoencoder.fit(X_train + noise, y_train)\n",
    "\n",
    "metric_denoising_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                             pipe_denoising_autoencoder.predict_proba(X_test), \n",
    "                                             average=\"weighted\")\n",
    "print(metric_denoising_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutional_autoencoder = ConvolutionalAutoencoder(input_shape=(int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))),\n",
    "                                                     n_epoch=50,\n",
    "                                                     batch_size=100,\n",
    "                                                     encoder_layers=3,\n",
    "                                                     decoder_layers=3,\n",
    "                                                     filters=100,\n",
    "                                                     kernel_size=5,\n",
    "                                                     strides=1,\n",
    "                                                     pool_size=4,\n",
    "                                                     encoding_dim=100,\n",
    "                                                     denoising=None)\n",
    "\n",
    "print(convolutional_autoencoder.autoencoder.summary())\n",
    "\n",
    "pipe_convolutional_autoencoder = Pipeline(steps=[(\"autoencoder\", convolutional_autoencoder),\n",
    "                                                 (\"scaler_classifier\", scaler_classifier),\n",
    "                                                 (\"classifier\", logistic)])\n",
    "\n",
    "pipe_convolutional_autoencoder = pipe_convolutional_autoencoder.fit(np.reshape(X_train, [X_train.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))]), \n",
    "                                                                    y_train)\n",
    "\n",
    "metric_convolutional_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                                 pipe_convolutional_autoencoder.predict_proba(np.reshape(X_test, [X_test.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))])),\n",
    "                                                 average=\"weighted\")\n",
    "print(metric_convolutional_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq2seq_autoencoder = Seq2SeqAutoencoder(input_shape=(int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))),\n",
    "                                         n_epoch=2,\n",
    "                                         batch_size=100,\n",
    "                                         encoder_layers=1,\n",
    "                                         decoder_layers=1,\n",
    "                                         n_hidden_units=5,\n",
    "                                         encoding_dim=5,\n",
    "                                         stateful=False,\n",
    "                                         unroll=False,\n",
    "                                         denoising=None)\n",
    "\n",
    "print(seq2seq_autoencoder.autoencoder.summary())\n",
    "\n",
    "pipe_seq2seq_autoencoder = Pipeline(steps=[(\"autoencoder\", seq2seq_autoencoder),\n",
    "                                           (\"scaler_classifier\", scaler_classifier),\n",
    "                                           (\"classifier\", logistic)])\n",
    "\n",
    "pipe_seq2seq_autoencoder = pipe_seq2seq_autoencoder.fit(np.reshape(X_train, [X_train.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))]),\n",
    "                                                        y_train)\n",
    "\n",
    "metric_seq2seq_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                           pipe_seq2seq_autoencoder.predict_proba(np.reshape(X_test, [X_test.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))])),\n",
    "                                           average=\"weighted\")\n",
    "print(metric_seq2seq_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoding_dim = 2\n",
    "\n",
    "variational_autoencoder = VariationalAutoencoder(n_feat=X_train.shape[1],\n",
    "                                                 n_epoch=50,\n",
    "                                                 batch_size=100,\n",
    "                                                 encoder_layers=3,\n",
    "                                                 decoder_layers=3,\n",
    "                                                 n_hidden_units=int(X_train.shape[1] / 2),\n",
    "                                                 encoding_dim=encoding_dim,\n",
    "                                                 denoising=None)\n",
    "\n",
    "print(variational_autoencoder.autoencoder.summary())\n",
    "\n",
    "pipe_variational_autoencoder = Pipeline(steps=[(\"autoencoder\", variational_autoencoder),\n",
    "                                               (\"scaler_classifier\", scaler_classifier),\n",
    "                                               (\"classifier\", logistic)])\n",
    "\n",
    "pipe_variational_autoencoder = pipe_variational_autoencoder.fit(X_train, y_train)\n",
    "\n",
    "metric_variational_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                               pipe_variational_autoencoder.predict_proba(X_test), \n",
    "                                               average=\"weighted\")\n",
    "print(metric_variational_autoencoder)\n",
    "\n",
    "if encoding_dim == 2:\n",
    "    test_encoded_df = pd.DataFrame(pipe_variational_autoencoder.named_steps[\"autoencoder\"].encoder.predict(X_test))\n",
    "    test_encoded_df[\"Target\"] = y_test\n",
    "    test_encoded_df.columns.values[0:2] = [\"Encoding_1\", \"Encoding_2\"]\n",
    "\n",
    "    scaler_plot = MinMaxScaler(feature_range=(0.25, 0.75))\n",
    "    scaler_plot = scaler_plot.fit(test_encoded_df[[\"Encoding_1\", \"Encoding_2\"]])\n",
    "    test_encoded_df[[\"Encoding_1\", \"Encoding_2\"]] = scaler_plot.transform(test_encoded_df[[\"Encoding_1\", \"Encoding_2\"]])\n",
    "\n",
    "    cluster_plot = ggplot(test_encoded_df) + \\\n",
    "    geom_point(aes(x=\"Encoding_1\", \n",
    "                   y=\"Encoding_2\", \n",
    "                   fill=\"factor(Target)\"),\n",
    "               size=1,\n",
    "               color = \"black\") + \\\n",
    "    xlab(\"Encoding dimension 1\") + \\\n",
    "    ylab(\"Encoding dimension 2\") + \\\n",
    "    ggtitle(\"Variational autoencoder with 2-dimensional encoding\") + \\\n",
    "    theme_matplotlib()\n",
    "    print(cluster_plot)\n",
    "\n",
    "    n = 15\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "    grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "    for i, xi in enumerate(grid_x):\n",
    "        for j, yi in enumerate(grid_y):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = pipe_variational_autoencoder.named_steps[\"autoencoder\"].generator.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size: (i + 1) * digit_size, j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.title(\"Variational autoencoder with 2-dimensional encoding\\nGenerating new images\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convolutional2D_autoencoder = Convolutional2DAutoencoder(input_shape=(int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5)), 1),\n",
    "                                                         n_epoch=50,\n",
    "                                                         batch_size=100,\n",
    "                                                         encoder_layers=3,\n",
    "                                                         decoder_layers=3,\n",
    "                                                         filters=10,\n",
    "                                                         kernel_size=5,\n",
    "                                                         strides=1,\n",
    "                                                         pool_size=4,\n",
    "                                                         encoding_dim=4,\n",
    "                                                         denoising=None)\n",
    "\n",
    "print(convolutional2D_autoencoder.autoencoder.summary())\n",
    "\n",
    "pipe_convolutional2D_autoencoder = Pipeline(steps=[(\"autoencoder\", convolutional2D_autoencoder),\n",
    "                                                   (\"scaler_classifier\", scaler_classifier),\n",
    "                                                   (\"classifier\", logistic)])\n",
    "\n",
    "pipe_convolutional2D_autoencoder = pipe_convolutional2D_autoencoder.fit(np.reshape(X_train, [X_train.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5)), 1]),\n",
    "                                                                        y_train)\n",
    "\n",
    "metric_convolutional2D_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                                   pipe_convolutional2D_autoencoder.predict_proba(np.reshape(X_test, [X_test.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5)), 1])),\n",
    "                                                   average=\"weighted\")\n",
    "print(metric_convolutional2D_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In development.\n",
    "# Some transfer learning stuff.\n",
    "# Probably will come in as another repo.\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "cifar = cifar10.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = cifar\n",
    "cifar[0][0][0, :, :, 0]\n",
    "x_train.shape[1:]\n",
    "\n",
    "autoencoder.layers[0:10]\n",
    "\n",
    "for layer in autoencoder.layers[0:10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "autoencoder.layers[9].output\n",
    "\n",
    "classifier_output = autoencoder.layers[9].output\n",
    "classifier_output = Dense(100, activation=\"elu\")(classifier_output)\n",
    "classifier_output = Dense(100, activation=\"elu\")(classifier_output)\n",
    "classifier_output = Dense(10, activation=\"softmax\")(classifier_output)\n",
    "\n",
    "model_final = Model(autoencoder.input, classifier_output)\n",
    "model_final.compile(loss = \"categorical_crossentropy\", \n",
    "                    optimizer=keras.optimizers.Adam(), \n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "model_final.fit(X_train, keras.utils.to_categorical(y_train, 10),\n",
    "                validation_split=0.3,\n",
    "                epochs=50,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                callbacks=callbacks_list, \n",
    "                verbose=2)\n",
    "\n",
    "model_final.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "              model_final.predict(X_test), \n",
    "              average=\"weighted\")\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    print (sess.run(c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
