{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Hamaad Musharaf Shah.\n",
    "# The following references were used.\n",
    "# https://keras.io\n",
    "# https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "# https://stackoverflow.com/questions/42177658/how-to-switch-backend-with-keras-from-tensorflow-to-theano\n",
    "# https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\n",
    "# http://scikit-learn.org/stable/\n",
    "# Book: Ian Goodfellow, Yoshua Bengio and Aaron Courville, \"Deep Learning\" - http://www.deeplearningbook.org\n",
    "# Book: Aurelien Geron, \"Hands-On Machine Learning with Scikit-Learn & Tensorflow\" - https://www.amazon.co.uk/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291\n",
    "\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "import keras\n",
    "from keras import backend as bkend\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from autoencoders_keras.get_session import get_session\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "KTF.set_session(get_session(gpu_fraction=0.25, allow_soft_placement=True))\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from autoencoders_keras.vanilla_autoencoder import VanillaAutoencoder\n",
    "from autoencoders_keras.convolutional_autoencoder import ConvolutionalAutoencoder\n",
    "from autoencoders_keras.convolutional2D_autoencoder import Convolutional2DAutoencoder\n",
    "from autoencoders_keras.seq2seq_autoencoder import Seq2SeqAutoencoder\n",
    "from autoencoders_keras.variational_autoencoder import VariationalAutoencoder\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "importlib.reload(bkend)\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "data_set = \"CIFAR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if data_set == \"MNIST\":\n",
    "    mnist = fetch_mldata(\"MNIST original\")\n",
    "    X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "    X = X.astype(\"float32\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=666)\n",
    "    X_train /= 255.0\n",
    "    X_test /= 255.0\n",
    "elif data_set == \"CIFAR\":\n",
    "    cifar = cifar10.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = cifar\n",
    "    y_train = y_train.ravel()\n",
    "    y_test = y_test.ravel()\n",
    "    X_train = X_train.astype(\"float32\")\n",
    "    X_test = X_test.astype(\"float32\")\n",
    "    X_train /= 255.0\n",
    "    X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler_classifier = MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "logistic = linear_model.LogisticRegression(random_state=666)\n",
    "lb = LabelBinarizer()\n",
    "lb = lb.fit(y_train.reshape(y_train.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_base = Pipeline(steps=[(\"scaler_classifier\", scaler_classifier),\n",
    "                            (\"classifier\", logistic)])\n",
    "pipe_base = pipe_base.fit(X_train, y_train)\n",
    "\n",
    "metric_base = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                            pipe_base.predict_proba(X_test), \n",
    "                            average=\"weighted\")\n",
    "print(metric_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    autoencoder = VanillaAutoencoder(n_feat=X_train.shape[1],\n",
    "                                     n_epoch=5,\n",
    "                                     batch_size=100,\n",
    "                                     encoder_layers=3,\n",
    "                                     decoder_layers=3,\n",
    "                                     n_hidden_units=int(X_train.shape[1] / 2),\n",
    "                                     encoding_dim=int(X_train.shape[1] / 2),\n",
    "                                     denoising=None)\n",
    "\n",
    "    print(autoencoder.autoencoder.summary())\n",
    "\n",
    "    pipe_autoencoder = Pipeline(steps=[(\"autoencoder\", autoencoder),\n",
    "                                       (\"scaler_classifier\", scaler_classifier),\n",
    "                                       (\"classifier\", logistic)])\n",
    "\n",
    "    pipe_autoencoder = pipe_autoencoder.fit(X_train, y_train)\n",
    "\n",
    "    metric_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                       pipe_autoencoder.predict_proba(X_test), \n",
    "                                       average=\"weighted\")\n",
    "    print(metric_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    noise = 0.10 * np.reshape(np.random.uniform(low=0.0, \n",
    "                                                high=1.0, \n",
    "                                                size=X_train.shape[0] * X_train.shape[1]), \n",
    "                              [X_train.shape[0], X_train.shape[1]])\n",
    "\n",
    "    denoising_autoencoder = VanillaAutoencoder(n_feat=X_train.shape[1],\n",
    "                                               n_epoch=5,\n",
    "                                               batch_size=100,\n",
    "                                               encoder_layers=3,\n",
    "                                               decoder_layers=3,\n",
    "                                               n_hidden_units=int(X_train.shape[1] / 2),\n",
    "                                               encoding_dim=int(X_train.shape[1] / 2),\n",
    "                                               denoising=noise)\n",
    "\n",
    "    print(denoising_autoencoder.autoencoder.summary())\n",
    "\n",
    "    pipe_denoising_autoencoder = Pipeline(steps=[(\"autoencoder\", denoising_autoencoder),\n",
    "                                                 (\"scaler_classifier\", scaler_classifier),\n",
    "                                                 (\"classifier\", logistic)])\n",
    "\n",
    "    pipe_denoising_autoencoder = pipe_denoising_autoencoder.fit(X_train, y_train)\n",
    "\n",
    "    metric_denoising_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                                 pipe_denoising_autoencoder.predict_proba(X_test), \n",
    "                                                 average=\"weighted\")\n",
    "    print(metric_denoising_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    convolutional_autoencoder = ConvolutionalAutoencoder(input_shape=(int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))),\n",
    "                                                         n_epoch=5,\n",
    "                                                         batch_size=100,\n",
    "                                                         encoder_layers=3,\n",
    "                                                         decoder_layers=3,\n",
    "                                                         filters=100,\n",
    "                                                         kernel_size=5,\n",
    "                                                         strides=1,\n",
    "                                                         pool_size=4,\n",
    "                                                         encoding_dim=14,\n",
    "                                                         denoising=None)\n",
    "\n",
    "    print(convolutional_autoencoder.autoencoder.summary())\n",
    "\n",
    "    pipe_convolutional_autoencoder = Pipeline(steps=[(\"autoencoder\", convolutional_autoencoder),\n",
    "                                                     (\"scaler_classifier\", scaler_classifier),\n",
    "                                                     (\"classifier\", logistic)])\n",
    "\n",
    "    pipe_convolutional_autoencoder = pipe_convolutional_autoencoder.fit(np.reshape(X_train, [X_train.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))]), \n",
    "                                                                        y_train)\n",
    "\n",
    "    metric_convolutional_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                                     pipe_convolutional_autoencoder.predict_proba(np.reshape(X_test, [X_test.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))])),\n",
    "                                                     average=\"weighted\")\n",
    "    print(metric_convolutional_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    seq2seq_autoencoder = Seq2SeqAutoencoder(input_shape=(int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))),\n",
    "                                             n_epoch=5,\n",
    "                                             batch_size=100,\n",
    "                                             encoder_layers=3,\n",
    "                                             decoder_layers=3,\n",
    "                                             n_hidden_units=50,\n",
    "                                             encoding_dim=14,\n",
    "                                             stateful=False,\n",
    "                                             denoising=None)\n",
    "\n",
    "    print(seq2seq_autoencoder.autoencoder.summary())\n",
    "\n",
    "    pipe_seq2seq_autoencoder = Pipeline(steps=[(\"autoencoder\", seq2seq_autoencoder),\n",
    "                                               (\"scaler_classifier\", scaler_classifier),\n",
    "                                               (\"classifier\", logistic)])\n",
    "\n",
    "    pipe_seq2seq_autoencoder = pipe_seq2seq_autoencoder.fit(np.reshape(X_train, [X_train.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))]),\n",
    "                                                            y_train)\n",
    "\n",
    "    metric_seq2seq_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                               pipe_seq2seq_autoencoder.predict_proba(np.reshape(X_test, [X_test.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5))])),\n",
    "                                               average=\"weighted\")\n",
    "    print(metric_seq2seq_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    encoding_dim = 2\n",
    "\n",
    "    variational_autoencoder = VariationalAutoencoder(n_feat=X_train.shape[1],\n",
    "                                                     n_epoch=5,\n",
    "                                                     batch_size=100,\n",
    "                                                     encoder_layers=3,\n",
    "                                                     decoder_layers=3,\n",
    "                                                     n_hidden_units=int(X_train.shape[1] / 2),\n",
    "                                                     encoding_dim=encoding_dim,\n",
    "                                                     denoising=None)\n",
    "\n",
    "    print(variational_autoencoder.autoencoder.summary())\n",
    "\n",
    "    pipe_variational_autoencoder = Pipeline(steps=[(\"autoencoder\", variational_autoencoder),\n",
    "                                                   (\"scaler_classifier\", scaler_classifier),\n",
    "                                                   (\"classifier\", logistic)])\n",
    "\n",
    "    pipe_variational_autoencoder = pipe_variational_autoencoder.fit(X_train, y_train)\n",
    "\n",
    "    metric_variational_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                                   pipe_variational_autoencoder.predict_proba(X_test), \n",
    "                                                   average=\"weighted\")\n",
    "    print(metric_variational_autoencoder)\n",
    "\n",
    "    if encoding_dim == 2:\n",
    "        test_encoded_df = pd.DataFrame(pipe_variational_autoencoder.named_steps[\"autoencoder\"].encoder.predict(X_test))\n",
    "        test_encoded_df[\"Target\"] = y_test\n",
    "        test_encoded_df.columns.values[0:2] = [\"Encoding_1\", \"Encoding_2\"]\n",
    "\n",
    "        scaler_plot = MinMaxScaler(feature_range=(0.25, 0.75))\n",
    "        scaler_plot = scaler_plot.fit(test_encoded_df[[\"Encoding_1\", \"Encoding_2\"]])\n",
    "        test_encoded_df[[\"Encoding_1\", \"Encoding_2\"]] = scaler_plot.transform(test_encoded_df[[\"Encoding_1\", \"Encoding_2\"]])\n",
    "\n",
    "        cluster_plot = ggplot(test_encoded_df) + \\\n",
    "        geom_point(aes(x=\"Encoding_1\", \n",
    "                       y=\"Encoding_2\", \n",
    "                       fill=\"factor(Target)\"),\n",
    "                   size=1,\n",
    "                   color = \"black\") + \\\n",
    "        xlab(\"Encoding dimension 1\") + \\\n",
    "        ylab(\"Encoding dimension 2\") + \\\n",
    "        ggtitle(\"Variational autoencoder with 2-dimensional encoding\") + \\\n",
    "        theme_matplotlib()\n",
    "        print(cluster_plot)\n",
    "\n",
    "        n = 15\n",
    "        digit_size = 28\n",
    "        figure = np.zeros((digit_size * n, digit_size * n))\n",
    "        grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "        grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "        for i, xi in enumerate(grid_x):\n",
    "            for j, yi in enumerate(grid_y):\n",
    "                z_sample = np.array([[xi, yi]])\n",
    "                x_decoded = pipe_variational_autoencoder.named_steps[\"autoencoder\"].generator.predict(z_sample)\n",
    "                digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "                figure[i * digit_size: (i + 1) * digit_size, j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(figure, cmap=\"Greys_r\")\n",
    "        plt.title(\"Variational autoencoder with 2-dimensional encoding\\nGenerating new images\")\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    convolutional2D_autoencoder = Convolutional2DAutoencoder(input_shape=(int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5)), 1),\n",
    "                                                             n_epoch=5,\n",
    "                                                             batch_size=100,\n",
    "                                                             encoder_layers=3,\n",
    "                                                             decoder_layers=3,\n",
    "                                                             filters=100,\n",
    "                                                             kernel_size=5,\n",
    "                                                             strides=1,\n",
    "                                                             pool_size=4,\n",
    "                                                             encoding_dim=14,\n",
    "                                                             denoising=None)\n",
    "\n",
    "    print(convolutional2D_autoencoder.autoencoder.summary())\n",
    "\n",
    "    pipe_convolutional2D_autoencoder = Pipeline(steps=[(\"autoencoder\", convolutional2D_autoencoder),\n",
    "                                                       (\"scaler_classifier\", scaler_classifier),\n",
    "                                                       (\"classifier\", logistic)])\n",
    "\n",
    "    pipe_convolutional2D_autoencoder = pipe_convolutional2D_autoencoder.fit(np.reshape(X_train, [X_train.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5)), 1]),\n",
    "                                                                            y_train)\n",
    "\n",
    "    metric_convolutional2D_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                                       pipe_convolutional2D_autoencoder.predict_proba(np.reshape(X_test, [X_test.shape[0], int(math.pow(X_train.shape[1], 0.5)), int(math.pow(X_train.shape[1], 0.5)), 1])),\n",
    "                                                       average=\"weighted\")\n",
    "    print(metric_convolutional2D_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    convolutional2D_autoencoder = Convolutional2DAutoencoder(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]),\n",
    "                                                             n_epoch=5,\n",
    "                                                             batch_size=100,\n",
    "                                                             encoder_layers=3,\n",
    "                                                             decoder_layers=3,\n",
    "                                                             filters=50,\n",
    "                                                             kernel_size=5,\n",
    "                                                             strides=1,\n",
    "                                                             pool_size=4,\n",
    "                                                             encoding_dim=16,\n",
    "                                                             denoising=None)\n",
    "\n",
    "    print(convolutional2D_autoencoder.autoencoder.summary())\n",
    "\n",
    "    pipe_convolutional2D_autoencoder = Pipeline(steps=[(\"autoencoder\", convolutional2D_autoencoder),\n",
    "                                                       (\"scaler_classifier\", scaler_classifier),\n",
    "                                                       (\"classifier\", logistic)])\n",
    "\n",
    "    pipe_convolutional2D_autoencoder = pipe_convolutional2D_autoencoder.fit(X_train, y_train)\n",
    "\n",
    "    metric_convolutional2D_autoencoder = roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "                                                       pipe_convolutional2D_autoencoder.predict_proba(X_test),\n",
    "                                                       average=\"weighted\")\n",
    "    print(metric_convolutional2D_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In development.\n",
    "# Some transfer learning stuff.\n",
    "# Probably will come in as another repo.\n",
    "autoencoder.layers[0:10]\n",
    "\n",
    "for layer in autoencoder.layers[0:10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "autoencoder.layers[9].output\n",
    "\n",
    "classifier_output = autoencoder.layers[9].output\n",
    "classifier_output = Dense(100, activation=\"elu\")(classifier_output)\n",
    "classifier_output = Dense(100, activation=\"elu\")(classifier_output)\n",
    "classifier_output = Dense(10, activation=\"softmax\")(classifier_output)\n",
    "\n",
    "model_final = Model(autoencoder.input, classifier_output)\n",
    "model_final.compile(loss = \"categorical_crossentropy\", \n",
    "                    optimizer=keras.optimizers.Adam(), \n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "model_final.fit(X_train, keras.utils.to_categorical(y_train, 10),\n",
    "                validation_split=0.3,\n",
    "                epochs=50,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                callbacks=callbacks_list, \n",
    "                verbose=2)\n",
    "\n",
    "model_final.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(lb.transform(y_test.reshape(y_test.shape[0], 1)), \n",
    "              model_final.predict(X_test), \n",
    "              average=\"weighted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
